{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<figure style=\"float:right\">\n",
    "<a href=\"http://c51.lbl.gov/~walkloud/callat/\">\n",
    "    <img\n",
    "    src=\"./data/callat_logo.png\"\n",
    "    width=\"150\"\n",
    "    alt=\"CalLat logo\"\n",
    "    /img>\n",
    "</a>\n",
    "</figure>\n",
    "\n",
    "# Jupyter notebook for CalLat 0vbb project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gvar as gv\n",
    "import lsqfit\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy as sp\n",
    "import scipy.special as spsp\n",
    "print(\"python version:\", sys.version)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"numpy  version:\", np.__version__)\n",
    "print(\"scipy  version:\", sp.__version__)\n",
    "print(\"lsqfit version:\", lsqfit.__version__)\n",
    "print(\"gvar   version:\", gv.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params['save_fig']=True\n",
    "#\n",
    "params['ensembles'] = ['l1648f211b580m013m065m838','l2448f211b580m0064m0640m828',\\\n",
    "                       'l2464f211b600m0102m0509m635','l2464f211b600m00507m0507m628','l3264f211b600m00507m0507m628','l4064f211b600m00507m0507m628','l4864f211b600m00184m0507m628',\\\n",
    "                       'l3296f211b630m0074m037m440','l4896f211b630m00363m0363m430']\n",
    "params['operators'] = ['LR','LR_colormix','S','S_colormix','V']\n",
    "params['ansatz'] = 'chipt'\n",
    "params['order'] = 2\n",
    "params['fv_flag'] = True\n",
    "params['ma_flag'] = False\n",
    "params['alphas_flag'] = False\n",
    "# priors\n",
    "priors = dict()\n",
    "N0LO = 10.0\n",
    "N1LO = 10.0\n",
    "N2LO = 12.0 #This width was chosen from a Bayes study, maximizing the logBayesFactor\n",
    "# O3\n",
    "priors['b0.V'] = gv.gvar(0.0,N0LO*1.0) # LO LEC\n",
    "priors['c1.V'] = gv.gvar(0.0,N1LO*1.0) # NLO counterterm\n",
    "priors['a1.V'] = gv.gvar(0.0,N1LO*1.0) # NLO symanzik\n",
    "priors['s1.V'] = gv.gvar(0.0,N1LO*1.0) # NLO one-loop\n",
    "priors['c2.V'] = gv.gvar(0.0,N2LO*1.0) # N2LO counterterm\n",
    "priors['a2.V'] = gv.gvar(0.0,N2LO*1.0) # N2LO symanzik\n",
    "priors['m2.V'] = gv.gvar(0.0,N2LO*1.0) # N2LO mixed\n",
    "# O1\n",
    "priors['b0.LR'] = gv.gvar(0.0,N0LO*1.0) # LO LEC\n",
    "priors['c1.LR'] = gv.gvar(0.0,N1LO*1.0) # NLO counterterm\n",
    "priors['a1.LR'] = gv.gvar(0.0,N1LO*1.0) # NLO symanzik\n",
    "priors['s1.LR'] = gv.gvar(0.0,N1LO*1.0) # NLO one-loop\n",
    "priors['c2.LR'] = gv.gvar(0.0,N2LO*1.0) # N2LO counterterm\n",
    "priors['a2.LR'] = gv.gvar(0.0,N2LO*1.0) # N2LO symanzik\n",
    "priors['m2.LR'] = gv.gvar(0.0,N2LO*1.0) # N2LO mixed\n",
    "# O2\n",
    "priors['b0.LR_colormix'] = gv.gvar(0.0,N0LO*1.0) # LO LEC\n",
    "priors['c1.LR_colormix'] = gv.gvar(0.0,N1LO*1.0) # NLO counterterm\n",
    "priors['a1.LR_colormix'] = gv.gvar(0.0,N1LO*1.0) # NLO symanzik\n",
    "priors['s1.LR_colormix'] = gv.gvar(0.0,N1LO*1.0) # NLO one-loop\n",
    "priors['c2.LR_colormix'] = gv.gvar(0.0,N2LO*1.0) # N2LO counterterm\n",
    "priors['a2.LR_colormix'] = gv.gvar(0.0,N2LO*1.0) # N2LO symanzik\n",
    "priors['m2.LR_colormix'] = gv.gvar(0.0,N2LO*1.0) # N2LO mixed\n",
    "# O4\n",
    "priors['b0.S'] = gv.gvar(0.0,N0LO*1.0) # LO LEC\n",
    "priors['c1.S'] = gv.gvar(0.0,N1LO*1.0) # NLO counterterm\n",
    "priors['a1.S'] = gv.gvar(0.0,N1LO*1.0) # NLO symanzik\n",
    "priors['s1.S'] = gv.gvar(0.0,N1LO*1.0) # NLO one-loop\n",
    "priors['c2.S'] = gv.gvar(0.0,N2LO*1.0) # N2LO counterterm\n",
    "priors['a2.S'] = gv.gvar(0.0,N2LO*1.0) # N2LO symanzik\n",
    "priors['m2.S'] = gv.gvar(0.0,N2LO*1.0) # N2LO mixed\n",
    "# O5\n",
    "priors['b0.S_colormix'] = gv.gvar(0.0,N0LO*1.0) # LO LEC\n",
    "priors['c1.S_colormix'] = gv.gvar(0.0,N1LO*1.0) # NLO counterterm\n",
    "priors['a1.S_colormix'] = gv.gvar(0.0,N1LO*1.0) # NLO symanzik\n",
    "priors['s1.S_colormix'] = gv.gvar(0.0,N1LO*1.0) # NLO one-loop\n",
    "priors['c2.S_colormix'] = gv.gvar(0.0,N2LO*1.0) # N2LO counterterm\n",
    "priors['a2.S_colormix'] = gv.gvar(0.0,N2LO*1.0) # N2LO symanzik\n",
    "priors['m2.S_colormix'] = gv.gvar(0.0,N2LO*1.0) # N2LO mixed\n",
    "\n",
    "# Physical parameters from PDG\n",
    "physical_params = dict()\n",
    "# http://pdg.lbl.gov/2016/tables/rpp2016-tab-mesons-light.pdf\n",
    "physical_params['mpi'] = gv.gvar(0.13957018, 0.00000035) # mpi +/- [GeV]\n",
    "# http://pdg.lbl.gov/2016/reviews/rpp2016-rev-pseudoscalar-meson-decay-cons.pdf\n",
    "physical_params['Fpi'] = gv.gvar(0.1302, 0.0017)/np.sqrt(2) # Fpi + ['GeV']\n",
    "# https://journals.aps.org/prd/abstract/10.1103/PhysRevD.93.094510\n",
    "# https://arxiv.org/pdf/1503.02769.pdf\n",
    "physical_params['w0'] = gv.gvar(0.1714,0.0015)\n",
    "\n",
    "# plot parameters\n",
    "plt.rcParams['text.latex.preamble'] = [\n",
    "    r'\\usepackage{helvet}',\n",
    "    r'\\usepackage{sansmath}',\n",
    "    r'\\sansmath']\n",
    "plot_params = dict()\n",
    "scale = 4.0\n",
    "plot_params['ms'] = str(scale*3)\n",
    "plot_params['cs'] = scale*3\n",
    "plot_params['fs_l'] = scale*7\n",
    "plot_params['fs_xy'] = scale*7\n",
    "plot_params['ts'] = scale*7\n",
    "plot_params['lw'] = scale*0.5\n",
    "gr = 1.618034333\n",
    "fs2_base = scale*3.50394\n",
    "plot_params['fig_size2'] = (fs2_base,fs2_base/gr)\n",
    "fs3_base = scale*3.50394\n",
    "plot_params['fig_size3'] = (fs3_base,fs3_base/gr)\n",
    "plot_params['plt_axes'] = [0.14,0.13,0.825,0.825]\n",
    "plot_params['op_color'] = {'V':'#c82506',\\\n",
    "                           'LR':'#70b741', 'LR_colormix':'#0b5d12',\\\n",
    "                           'S': '#51a7f9', 'S_colormix':'#00397a'}\n",
    "plot_params['alat_color'] = {'a15':'#c82506','a12':'#70b741','a09':'#51a7f9'}\n",
    "plot_params['mpi_shape'] = {'m130':'o', 'm220':'^', 'm310':'s'}\n",
    "plot_params['a_shape'] = {'a09':'H', 'a12':'d', 'a15':'s'}\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', size=plot_params['fs_xy']) # for sci notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_0vbb = pd.read_csv('./data/n0bb_v3.csv')\n",
    "#data_0vbb.groupby(['hisq_ensembles','operator']).describe()['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_mm = pd.read_csv('./data/phi_ju.csv')\n",
    "#data_mm.groupby(['ensemble']).describe()['E0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hisq_parameters = pd.read_csv('./data/hisq_params.csv')\n",
    "#hisq_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a015 = ['l1648f211b580m013m065m838','l2448f211b580m0064m0640m828','l3248f211b580m00235m0647m831']\n",
    "a012 = ['l2464f211b600m0102m0509m635',\\\n",
    "        'l2464f211b600m00507m0507m628','l3264f211b600m00507m0507m628','l4064f211b600m00507m0507m628',\\\n",
    "        'l4864f211b600m00184m0507m628']\n",
    "a009 = ['l3296f211b630m0074m037m440','l4896f211b630m00363m0363m430']\n",
    "def e2s():\n",
    "    ensemble_to_spacing=dict({i:'a15' for i in a015})\n",
    "    ensemble_to_spacing.update({i:'a12' for i in a012})\n",
    "    ensemble_to_spacing.update({i:'a09' for i in a009})\n",
    "    return ensemble_to_spacing\n",
    "m310 = ['l1648f211b580m013m065m838','l2464f211b600m0102m0509m635','l3296f211b630m0074m037m440']\n",
    "m220 = ['l2448f211b580m0064m0640m828',\\\n",
    "        'l2464f211b600m00507m0507m628','l3264f211b600m00507m0507m628','l4064f211b600m00507m0507m628',\\\n",
    "        'l4896f211b630m00363m0363m430']\n",
    "m130 = ['l3248f211b580m00235m0647m831','l4864f211b600m00184m0507m628']\n",
    "def e2m():\n",
    "    ensemble_to_mpi=dict({i:'m310' for i in m310})\n",
    "    ensemble_to_mpi.update({i:'m220' for i in m220})\n",
    "    ensemble_to_mpi.update({i:'m130' for i in m130})\n",
    "    return ensemble_to_mpi\n",
    "lbl = {e:None for e in params['ensembles']}\n",
    "lbl['l1648f211b580m013m065m838'] = r'$a\\sim0.15$\\textrm{ fm}'\n",
    "lbl['l2464f211b600m0102m0509m635'] = r'$a\\sim0.12$\\textrm{ fm}'\n",
    "lbl['l3296f211b630m0074m037m440'] = r'$a\\sim0.09$\\textrm{ fm}'\n",
    "print(lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renormalization matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dzmat = dict()\n",
    "dzmat['a15'] = gv.gvar([['0.9407(63)',       '0(0)',       '0(0)',       '0(0)',       '0(0)'],\\\n",
    "                        [      '0(0)', '0.9835(68)','-0.0106(18)',       '0(0)',       '0(0)'],\\\n",
    "                        [      '0(0)','-0.0369(30)', '1.0519(80)',       '0(0)',       '0(0)'],\\\n",
    "                        [      '0(0)',       '0(0)',       '0(0)',  '1.020(11)','-0.0356(49)'],\\\n",
    "                        [      '0(0)',       '0(0)',       '0(0)','-0.0485(31)', '0.9519(68)']])\n",
    "\n",
    "dzmat['a12'] = gv.gvar([['0.9117(43)',       '0(0)',       '0(0)',       '0(0)',       '0(0)'],\\\n",
    "                        [      '0(0)', '0.9535(48)','-0.0130(17)',       '0(0)',       '0(0)'],\\\n",
    "                        [      '0(0)','-0.0284(30)', '0.9922(60)',       '0(0)',       '0(0)'],\\\n",
    "                        [      '0(0)',       '0(0)',       '0(0)', '0.9656(96)','-0.0275(49)'],\\\n",
    "                        [      '0(0)',       '0(0)',       '0(0)','-0.0360(28)', '0.9270(50)']])\n",
    "\n",
    "dzmat['a09'] = gv.gvar([['0.9017(39)',       '0(0)',       '0(0)',       '0(0)',       '0(0)'],\\\n",
    "                        [      '0(0)', '0.9483(44)','-0.0269(17)',       '0(0)',       '0(0)'],\\\n",
    "                        [      '0(0)','-0.0236(29)', '0.9369(54)',       '0(0)',       '0(0)'],\\\n",
    "                        [      '0(0)',       '0(0)',       '0(0)', '0.9209(91)','-0.0224(49)'],\\\n",
    "                        [      '0(0)',       '0(0)',       '0(0)','-0.0230(28)', '0.9332(47)']])\n",
    "# V LR LR_colormix S S_colormix\n",
    "# O3 O1 O2 O4 O5\n",
    "ensemble_to_spacing = e2s()\n",
    "operator_to_index = {'V':0,'LR':1,'LR_colormix':2,'S':3,'S_colormix':4}\n",
    "def zmat(ensemble,operator_list):\n",
    "    alat = ensemble_to_spacing[ensemble]\n",
    "    operator_index = [operator_to_index[op] for op in operator_list]\n",
    "    return dzmat[alat][np.ix_(operator_index,operator_index)]\n",
    "# test\n",
    "zmat('l1648f211b580m013m065m838',['V','LR','S'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 0vbb data\n",
    "dict_0vbb = {(ens,op): -1.*data_0vbb.query(\"hisq_ensembles=='%s' and operator=='%s' and fit_n==1\"%(ens,op))\\\n",
    "             .sort_values('nbs')['result'].as_matrix()\\\n",
    "             for ens in params['ensembles']\\\n",
    "             for op in params['operators']}\n",
    "dict_0vbb.update({(ens,'epi'): data_0vbb.query(\"hisq_ensembles=='%s' and operator=='epi' and fit_n==1\" %(ens))\\\n",
    "          .sort_values('nbs')['result'].as_matrix()\\\n",
    "          for ens in params['ensembles']})\n",
    "dict_0vbb.update({(ens,'fpi'): 1./data_0vbb.query(\"hisq_ensembles=='%s' and operator=='fpi' and fit_n==0\" %(ens))\\\n",
    "          .sort_values('nbs')['result'].as_matrix()\\\n",
    "          for ens in params['ensembles']})\n",
    "gv_0vbb = gv.dataset.avg_data(dict_0vbb,bstrap=True)\n",
    "# split data from prior\n",
    "gv_y = {(ens,op):gv_0vbb[(ens,op)] for ens in params['ensembles'] for op in params['operators']}\n",
    "gv_efpi = {(ens,op):gv_0vbb[(ens,op)] for ens in params['ensembles'] for op in ['epi','fpi']}\n",
    "# \n",
    "dict_gVmm = {(ens,'phi_ju'): data_mm.query(\"ensemble=='%s'\" %(ens)).sort_values('nbs')['E0'].as_matrix()\\\n",
    "                for ens in params['ensembles']}\n",
    "dict_gVmm[('l2464f211b600m00507m0507m628','phi_ju')] = data_mm.query(\"ensemble=='l3264f211b600m00507m0507m628'\").sort_values('nbs')['E0'].as_matrix()\n",
    "dict_gVmm[('l4064f211b600m00507m0507m628','phi_ju')] = data_mm.query(\"ensemble=='l3264f211b600m00507m0507m628'\").sort_values('nbs')['E0'].as_matrix()\n",
    "gv_gVmm = gv.dataset.avg_data(dict_gVmm,bstrap=True)\n",
    "gv_mm = {(ens,'phi_ju'):gv_gVmm[(ens,'phi_ju')] for ens in params['ensembles']}\n",
    "#\n",
    "gv_hisq = dict()\n",
    "for ens in params['ensembles']:\n",
    "    hp_ens = hisq_parameters.query(\"ensemble=='%s'\" %(ens))\n",
    "    gv_hisq[(ens,'aw0')] = gv.gvar(hp_ens['aw0_mean'].as_matrix()[0],hp_ens['aw0_sdev'].as_matrix()[0])\n",
    "    gv_hisq[(ens,'r2di')] = gv.gvar(hp_ens['r2DI_mean'].as_matrix()[0],hp_ens['r2DI_sdev'].as_matrix()[0])\n",
    "    gv_hisq[(ens,'r1a')] = gv.gvar(hp_ens['r1a_mean'].as_matrix()[0],hp_ens['r1a_sdev'].as_matrix()[0])\n",
    "gv_hisq.update({(ens,'a2di'):gv_hisq[(ens,'r2di')]/gv_hisq[(ens,'r1a')]**2 for ens in params['ensembles']})\n",
    "# renormalize y\n",
    "gv_rey = dict()\n",
    "for ens in params['ensembles']:\n",
    "    melem = np.array([gv_y[(ens,op)] for op in params['operators']])\n",
    "    rmatrix = zmat(ens,params['operators'])\n",
    "    relem = rmatrix.dot(melem.T)\n",
    "    for idx,op in enumerate(params['operators']):\n",
    "        gv_rey[(ens,op)] = relem[idx]/gv_hisq[(ens,'aw0')]**4 # convert data to w0 units\n",
    "\n",
    "# make x\n",
    "x = [[ens, op] for ens in params['ensembles'] for op in params['operators']]\n",
    "\n",
    "# make p\n",
    "def filter_priors(key):\n",
    "    if (int(key[1]) <= params['order'] and key.split('.')[1] in params['operators']):\n",
    "        pfilter = True\n",
    "    else: pfilter = False\n",
    "    if key.split('.')[0][0] in ['s'] and not params['alphas_flag']:\n",
    "        pfilter = False\n",
    "    return pfilter\n",
    "gv_p = {key:priors[key] for key in priors.keys()\\\n",
    "        if filter_priors(key)}\n",
    "gv_p.update(gv_efpi)\n",
    "gv_p.update({(ens,'ema'):gv_mm[(ens,'phi_ju')]/(4.*np.pi*gv_efpi[(ens,'fpi')]) for ens in params['ensembles']})\n",
    "gv_p.update({(ens,'epq2'):gv_hisq[(ens,'a2di')]/(4.*np.pi*gv_efpi[(ens,'fpi')])**2 for ens in params['ensembles']})\n",
    "gv_p.update({(ens,'ea2'):gv_hisq[(ens,'aw0')]**2/(4.*np.pi) for ens in params['ensembles']})\n",
    "# make variables for fit class initialization\n",
    "ini = dict()\n",
    "for ens in params['ensembles']:\n",
    "    ini[(ens,'alpha_s')] = hisq_parameters.query(\"ensemble=='%s'\" %(ens))['alfs'].as_matrix()[0]\n",
    "    ini[(ens,'mpiL')] = (float(ens[1:3])*gv_p[(ens,'epi')]*4.*np.pi*gv_p[(ens,'fpi')]).mean\n",
    "    ini[(ens,'mmaL')] = (float(ens[1:3])*gv_mm[(ens,'phi_ju')]).mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "short_name={\n",
    "    'l1648f211b580m013m065m838':'a15m310 ',\n",
    "    'l2448f211b580m0064m0640m828':'a15m220 ',\n",
    "    'l2464f211b600m0102m0509m635':'a12m310 ',\n",
    "    'l2464f211b600m00507m0507m628':'a12m220S',\n",
    "    'l3264f211b600m00507m0507m628':'a12m220 ',\n",
    "    'l4064f211b600m00507m0507m628':'a12m220L',\n",
    "    'l4864f211b600m00184m0507m628':'a12m130 ',\n",
    "    'l3296f211b630m0074m037m440':'a09m310 ',\n",
    "    'l4896f211b630m00363m0363m430':'a09m220'\n",
    "}\n",
    "if False:\n",
    "    for i,ens in enumerate(params['ensembles']):\n",
    "        print(gv_gV[(ens,'gV')],short_name[ens])\n",
    "if False:\n",
    "    for i,ens in enumerate(params['ensembles']):\n",
    "        print(\"%.5f +- %.5f\" %(dict_0vbb[(ens,'epi')].mean(),dict_0vbb[(ens,'epi')].std()),short_name[ens])\n",
    "if False:\n",
    "    x_epi=[dict_0vbb[(ens,'epi')].mean() for ens in params['ensembles']]\n",
    "    aLam = [4.*np.pi*dict_0vbb[(ens,'fpi')].mean() for ens in params['ensembles']]\n",
    "    e_aLam = [4.*np.pi*dict_0vbb[(ens,'fpi')].std() for ens in params['ensembles']]\n",
    "    aw0 = [hisq_parameters.query(\"ensemble=='%s'\" %(ens))['aw0_mean'].as_matrix()[0] for ens in params['ensembles']]\n",
    "    w0Lam = [4.*np.pi*dict_0vbb[(ens,'fpi')].mean()/aw0[i] for i,ens in enumerate(params['ensembles'])]\n",
    "    e_w0Lam = [4.*np.pi*dict_0vbb[(ens,'fpi')].std()/aw0[i] for i,ens in enumerate(params['ensembles'])]\n",
    "    for i,ens in enumerate(params['ensembles']):\n",
    "        print(short_name[ens],\n",
    "              '%.4f' %aw0[i],dict_0vbb[(ens,'fpi')].mean())\n",
    "    fig = plt.figure('aLam')\n",
    "    ax = plt.axes([0.14,0.165,0.825,0.825])\n",
    "    ax.errorbar(x_epi,aLam,yerr=e_aLam,marker='o',linestyle='None')\n",
    "    fig = plt.figure('w0Lam')\n",
    "    ax = plt.axes([0.14,0.165,0.825,0.825])\n",
    "    ax.errorbar(x_epi,w0Lam,yerr=e_w0Lam,marker='o',linestyle='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class fit_class(object):\n",
    "    def __init__(self,ansatz,order=1,fv_flag=False,ma_flag=False,alphas_flag=False,ini=None):\n",
    "        self.ansatz = ansatz\n",
    "        self.order = order\n",
    "        self.fv_flag = fv_flag\n",
    "        self.ma_flag = ma_flag\n",
    "        self.alphas_flag = alphas_flag\n",
    "        if alphas_flag:\n",
    "            ensembles = [k[0] for k in ini.keys() if k[1] is 'alpha_s']\n",
    "            self.alpha_s = {ens:ini[(ens,'alpha_s')] for ens in ensembles}\n",
    "        if self.fv_flag:\n",
    "            absn_multiplicity = np.array([6,12,8,6,24,24,0,12,30,24,24,8,24,48,0,6,48,36,24,24]) # |n| multiplicity\n",
    "            absn = np.sqrt(np.arange(1,len(absn_multiplicity)+1)) # L2 length in 3D\n",
    "            ensembles = [k[0] for k in ini.keys() if k[1] is 'mpiL']\n",
    "            mpiLn = {ens:absn*ini[(ens,'mpiL')] for ens in ensembles}\n",
    "            K1 = {ens:spsp.kn(1,mpiLn[ens]) for ens in ensembles}\n",
    "            self.fv_correction = {(ens,'log'): 4.*np.sum(absn_multiplicity*K1[ens]/mpiLn[ens]) for ens in ensembles}\n",
    "            if self.ma_flag:\n",
    "                mmaLn = {ens:absn*ini[(ens,'mmaL')] for ens in ensembles}\n",
    "                K1 = {ens:spsp.kn(1,mmaLn[ens]) for ens in ensembles}\n",
    "                self.fv_correction.update({(ens,'malog'): 4.*np.sum(absn_multiplicity*K1[ens]/mmaLn[ens])\\\n",
    "                                           for ens in ensembles})\n",
    "                K0 = {ens:spsp.kn(0,mpiLn[ens]) for ens in ensembles}\n",
    "                self.fv_correction.update({(ens,'pqlog'): 1.-2.*np.sum(absn_multiplicity*K0[ens])\\\n",
    "                                           for ens in ensembles})\n",
    "        self.ensembles = ['l1648f211b580m013m065m838','l2448f211b580m0064m0640m828',\\\n",
    "                       'l2464f211b600m0102m0509m635','l2464f211b600m00507m0507m628','l3264f211b600m00507m0507m628','l4064f211b600m00507m0507m628','l4864f211b600m00184m0507m628',\\\n",
    "                       'l3296f211b630m0074m037m440','l4896f211b630m00363m0363m430']\n",
    "    def fvlog(self,ens,epi):\n",
    "        r = np.log(epi**2)\n",
    "        if self.fv_flag:\n",
    "            r += self.fv_correction[(ens,'log')]\n",
    "        return r\n",
    "    def mafvlog(self,ens,ema):\n",
    "        r = np.log(ema**2)\n",
    "        if self.fv_flag and not self.ma_flag:\n",
    "            r += self.fv_correction[(ens,'log')]\n",
    "        elif self.fv_flag:\n",
    "            r += self.fv_correction[(ens,'malog')]\n",
    "        return r\n",
    "    def pqlog(self,ens,epi):\n",
    "        r = 1 + np.log(epi**2)\n",
    "        if self.fv_flag:\n",
    "            r += self.fv_correction[(ens,'pqlog')]\n",
    "        return r\n",
    "    def LO_analytic(self,x,p):\n",
    "        ens = x[0]\n",
    "        op = x[1]\n",
    "        epi = p[(ens,'epi')]\n",
    "        ea2 = p[(ens,'ea2')]\n",
    "        r = p['c1.%s' %op]*epi**2+p['a1.%s' %op]*ea2\n",
    "        if self.alphas_flag:\n",
    "            r += self.alpha_s[ens]*p['s1.%s' %op]*ea2\n",
    "        return r\n",
    "    def NLO_analytic(self,x,p):\n",
    "        ens = x[0]\n",
    "        op = x[1]\n",
    "        epi = p[(ens,'epi')]\n",
    "        ea2 = p[(ens,'ea2')]\n",
    "        r = p['a2.%s' %op]*ea2**2+p['c2.%s' %op]*epi**4+p['m2.%s' %op]*epi**2*ea2\n",
    "        return r\n",
    "    def xpt(self,x,p):\n",
    "        # unpack parameters\n",
    "        ens = x[0]\n",
    "        op = x[1]\n",
    "        epi = p[(ens,'epi')]\n",
    "        ea2 = p[(ens,'ea2')]\n",
    "        Lam = 4.*np.pi*p[(ens,'fpi')]\n",
    "        coeff = p['b0.%s' %op]*Lam**4/(4.*np.pi)**2\n",
    "        if self.ma_flag:\n",
    "            ema = p[(ens,'ema')]\n",
    "            epq2 = p[(ens,'epq2')]\n",
    "        else:\n",
    "            ema = p[(ens,'epi')]\n",
    "            epq2 = 0\n",
    "        # O1,O2,O4,O5\n",
    "        if op in ['LR','LR_colormix','S','S_colormix']:\n",
    "            r = coeff * (1.+2.*ema**2*self.mafvlog(ens,ema)+1./3.*epi**2*self.fvlog(ens,epi))\n",
    "            r += coeff * self.LO_analytic(x,p)\n",
    "            if op in ['S','S_colormix'] and self.ma_flag:\n",
    "                r += coeff * (-2.*epq2*self.pqlog(ens,epi))\n",
    "            if self.order > 1:\n",
    "                r += coeff * self.NLO_analytic(x,p)\n",
    "        # O3\n",
    "        if op in ['V']:\n",
    "            coeff = coeff * epi**2\n",
    "            r = coeff * (1.+2.*ema**2*self.mafvlog(ens,ema)-2./3.*epi**2*self.fvlog(ens,epi))\n",
    "            r += coeff * self.LO_analytic(x,p)\n",
    "            if self.order > 1:\n",
    "                r += coeff * self.NLO_analytic(x,p)\n",
    "        # convert from a^4 to w0^4\n",
    "        if ens in self.ensembles:\n",
    "            w0a4 = (1./(4.*np.pi*ea2))**2\n",
    "            r = w0a4*r\n",
    "        return r\n",
    "    def fit_function(self,x,p):\n",
    "        result = dict()\n",
    "        for xi in x:\n",
    "            result[(xi[0],xi[1])] = self.xpt(xi,p)\n",
    "        return result\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extrapolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initiate fit class\n",
    "FitClass = fit_class(params['ansatz'],params['order'],params['fv_flag'],params['ma_flag'],params['alphas_flag'],ini)\n",
    "fit = lsqfit.nonlinear_fit(data=(x,gv_rey),prior=gv_p,fcn=FitClass.fit_function,fitter='scipy_least_squares',debug=True)\n",
    "print(fit.format(pstyle='vv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# physical point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# physical point fit class\n",
    "FitClassP = fit_class(params['ansatz'],params['order'],fv_flag=False,ma_flag=False,alphas_flag=False,ini=None)\n",
    "x_physical = [['physical',op] for op in params['operators']]\n",
    "p_physical = {key:fit.p[key] for key in fit.p.keys() if key in priors.keys()}\n",
    "epi_phys = physical_params['mpi']/(4.*np.pi*physical_params['Fpi'])\n",
    "p_physical.update({('physical','epi'):epi_phys,\\\n",
    "                   ('physical','fpi'):physical_params['Fpi'],\\\n",
    "                   ('physical','ea2'):0.0})\n",
    "physical_result = FitClassP.fit_function(x_physical,p_physical)\n",
    "# matrix elements\n",
    "sme = ','.join([k for k in params['operators']]) + '\\n'\n",
    "sme += ','.join(['%.16f' %physical_result[('physical',k)].mean for k in params['operators']])\n",
    "smesdev = ','.join(['%.16f' %physical_result[('physical',k)].sdev for k in params['operators']]) + '\\n'\n",
    "# matrix element correlations\n",
    "correlations = gv.evalcorr(physical_result)\n",
    "scorr = ','.join([k for k in params['operators']]) + '\\n'\n",
    "for k1 in params['operators']:\n",
    "    for k2 in params['operators']:\n",
    "        scorr += '%.16f,' %correlations[(('physical',k1),('physical',k2))][0,0]\n",
    "    scorr = '%s\\n' %scorr[:-1]\n",
    "# LEC\n",
    "lec_list = np.array([['b0.%s' %k, 'c1.%s' %k] for k in params['operators']]).flatten()\n",
    "slecmean = ','.join(lec_list) + '\\n'\n",
    "slecmean += ','.join(['%.16f' %fit.p[k].mean for k in lec_list])\n",
    "slecsdev = ','.join(['%.16f' %fit.p[k].sdev for k in lec_list]) + '\\n'\n",
    "# LEC correlations\n",
    "lec_correlations = gv.evalcorr({k:fit.p[k] for k in lec_list})\n",
    "slec = ','.join(lec_list) + '\\n'\n",
    "for k1 in lec_list:\n",
    "    for k2 in lec_list:\n",
    "        slec += '%.16f,' %lec_correlations[(k1,k2)][0,0]\n",
    "    slec = '%s\\n' %slec[:-1]\n",
    "# prints\n",
    "print('Physical point matrix elements')\n",
    "for k in params['operators']:\n",
    "    print(\"%11s = %s\" %(k,physical_result[('physical',k)]))\n",
    "print('\\n')\n",
    "print('matrix elements')\n",
    "print(sme)\n",
    "print(smesdev)\n",
    "print('correlation matrix')\n",
    "print(scorr)\n",
    "print('LEC')\n",
    "print(slecmean)\n",
    "print(slecsdev)\n",
    "print('LEC correlation matrix')\n",
    "print(slec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data correct for fvshift and Fpi\n",
    "if not params['ma_flag']:\n",
    "    fullfit = FitClass.fit_function(x,fit.p)\n",
    "    FitClassNoFV = fit_class(params['ansatz'],params['order'],False,params['ma_flag'],params['alphas_flag'],ini)\n",
    "    nofvfit = FitClassNoFV.fit_function(x,fit.p)\n",
    "    diff = {key:fullfit[key]-nofvfit[key] for key in fullfit.keys()}\n",
    "    data_fvcorrected = {key:(physical_params['Fpi']/(fit.p[(key[0],'fpi')]/gv_hisq[(key[0],'aw0')]))**4*(gv_rey[key]-diff[key]) for key in gv_rey.keys()}\n",
    "    epi_data = {(ens,'epi'):fit.p[ens,'epi'] for ens in params['ensembles']}\n",
    "    # continuum extrapolation\n",
    "    epi_cont = np.linspace(0.001,0.3,50)\n",
    "    x_cont = [[idx,op] for idx,ec in enumerate(epi_cont) for op in params['operators']]\n",
    "    p_cont = {key:fit.p[key] for key in fit.p.keys() if key in priors.keys()}\n",
    "    p_cont.update({(idx,'epi'):ec for idx,ec in enumerate(epi_cont)})\n",
    "    p_cont.update({(idx,'fpi'):physical_params['Fpi'] for idx,ec in enumerate(epi_cont)})\n",
    "    p_cont.update({(idx,'ea2'):0.0 for idx,ec in enumerate(epi_cont)})\n",
    "    FitClassP = fit_class(params['ansatz'],params['order'],fv_flag=False,ma_flag=False,alphas_flag=False,ini=None)\n",
    "    contfit = FitClassP.fit_function(x_cont,p_cont)\n",
    "    x_continuum = epi_cont\n",
    "    y_continuum = {op:[contfit[(j,op)] for j,ec in enumerate(x_continuum)] for op in params['operators']}\n",
    "    # finite lattice spacing interpolation\n",
    "    ensemble_to_spacing = e2s()\n",
    "    ea2u = np.array([[ensemble_to_spacing[ens],gv_p[(ens,'ea2')]] for ens in params['ensembles']])\n",
    "    ea2uidx = np.unique(ea2u[:,0],return_index=True)\n",
    "    ea2label = ea2uidx[0]\n",
    "    ea2unique = ea2u[ea2uidx[1]][:,1]\n",
    "    epi_alat = epi_cont\n",
    "    x_alat = [[(idx1,idx2),op] for idx1,ec in enumerate(epi_cont) for idx2,ea2u in enumerate(ea2unique) for op in params['operators']]\n",
    "    p_alat = {key:fit.p[key] for key in fit.p.keys() if key in priors.keys()}\n",
    "    p_alat.update({((idx1,idx2),'epi'):ec for idx1,ec in enumerate(epi_alat) for idx2,ea2u in enumerate(ea2unique)})\n",
    "    p_alat.update({((idx1,idx2),'fpi'):physical_params['Fpi'] for idx1,ec in enumerate(epi_alat) for idx2,ea2u in enumerate(ea2unique)})\n",
    "    p_alat.update({((idx1,idx2),'ea2'):ea2u for idx1,ec in enumerate(epi_alat) for idx2,ea2u in enumerate(ea2unique)})\n",
    "    alatfit = FitClassNoFV.fit_function(x_alat,p_alat)\n",
    "    x_finitelattice = epi_alat\n",
    "    y_finitelattice = {op:{ea2label[k]:[alatfit[((j,k),op)] for j,ec in enumerate(x_continuum)]\\\n",
    "                           for k,ea2u in enumerate(ea2unique)}\\\n",
    "                       for op in params['operators']}\n",
    "else:\n",
    "    print(\"Mixed action fit, skipping plot routines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot result\n",
    "def plot_result(epi_data,data_fvcorrected,x_continuum,y_continuum,x_finitelattice,y_finitelattice,oplist,fig_name):\n",
    "    fig = plt.figure('%s chiral extrapolation' %params['ansatz'],figsize=plot_params['fig_size3'])\n",
    "    ax = plt.axes(plot_params['plt_axes'])\n",
    "    dict_e2s = e2s()\n",
    "    dict_e2m = e2m()\n",
    "    for oi,op in enumerate(oplist):\n",
    "        op_color = plot_params['op_color'][op]\n",
    "        # plot data\n",
    "        for ens in params['ensembles']:\n",
    "            a_color = plot_params['alat_color'][dict_e2s[ens]]\n",
    "            m_shape = plot_params['mpi_shape'][dict_e2m[ens]]\n",
    "            a_shape = plot_params['a_shape'][dict_e2s[ens]]\n",
    "            xdata = epi_data[(ens,'epi')].mean\n",
    "            ydata_mean = data_fvcorrected[(ens,op)].mean\n",
    "            ydata_sdev = data_fvcorrected[(ens,op)].sdev\n",
    "            if oi == len(oplist)-1:\n",
    "                if len(oplist) == 5:\n",
    "                    clr = 'k'\n",
    "                else:\n",
    "                    clr = op_color\n",
    "                ax.errorbar(x=xdata+100,y=ydata_mean,yerr=ydata_sdev,ls='None',marker=a_shape,\\\n",
    "                            mfc=clr,mec=clr,ecolor=clr,\\\n",
    "                            markersize=plot_params['ms'],elinewidth=plot_params['lw'],\\\n",
    "                            capsize=plot_params['cs'],mew=plot_params['lw'],\\\n",
    "                            label=lbl[ens])\n",
    "            ax.errorbar(x=xdata,y=ydata_mean,yerr=ydata_sdev,ls='None',marker=a_shape,\\\n",
    "                        mfc=op_color,mec=op_color,ecolor=op_color,\\\n",
    "                        markersize=plot_params['ms'],elinewidth=plot_params['lw'],\\\n",
    "                        capsize=plot_params['cs'],mew=plot_params['lw'])\n",
    "        a_color = plot_params['alat_color']\n",
    "        # plot continuum\n",
    "        x_continuum = x_continuum\n",
    "        y_continuum_mean = np.array([i.mean for i in y_continuum[op]])\n",
    "        y_continuum_sdev = np.array([i.sdev for i in y_continuum[op]])\n",
    "        ax.errorbar(x=x_continuum,y=y_continuum_mean,ls='-',color=op_color)\n",
    "        ax.fill_between(x_continuum,y_continuum_mean+y_continuum_sdev,y_continuum_mean-y_continuum_sdev,\\\n",
    "                        color=op_color,alpha=0.3)\n",
    "        # plot finite lattice spacing\n",
    "        x_finitelattice = x_finitelattice\n",
    "        y_finitelattice_mean = {alat:np.array([i.mean for i in y_finitelattice[op][alat]]) for alat in ea2label}\n",
    "        y_finitelattice_sdev = {alat:np.array([i.sdev for i in y_finitelattice[op][alat]]) for alat in ea2label}\n",
    "        for alat in ea2label:\n",
    "            ax.errorbar(x=x_finitelattice,y=y_finitelattice_mean[alat],ls='--',color=op_color,alpha=.75)\n",
    "    # physical pion\n",
    "    epi_phys = physical_params['mpi']/(4.*np.pi*physical_params['Fpi'])\n",
    "    ax.axvspan(epi_phys.mean-epi_phys.sdev, epi_phys.mean+epi_phys.sdev, alpha=0.4, color='#a6aaa9')\n",
    "    ax.axvline(epi_phys.mean,ls='--',color='#a6aaa9',lw=plot_params['lw'])\n",
    "    yi,yf = ax.get_ylim()[0],ax.get_ylim()[1]\n",
    "    ax.set_ylim([yi,yf])\n",
    "    ax.set_xlim([0.0,0.3])\n",
    "    #print(ax.get_ylim())\n",
    "    ax.set_xlabel('$\\epsilon_\\pi=m_\\pi/(4\\pi F_\\pi)$', fontsize=plot_params['fs_xy'])\n",
    "    ax.set_ylabel('$O_i$ [GeV${}^4$]', fontsize=plot_params['fs_xy'])\n",
    "    if oplist == ['V']:\n",
    "        ax.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    ax.xaxis.set_tick_params(labelsize=plot_params['ts'],width=plot_params['lw'])\n",
    "    ax.yaxis.set_tick_params(labelsize=plot_params['ts'],width=plot_params['lw'])\n",
    "    [ax.spines[i].set_linewidth(plot_params['lw']) for i in ax.spines]\n",
    "    ax.legend(loc=2,fontsize=plot_params['fs_xy'])\n",
    "    plt.draw()\n",
    "    if params['save_fig']:\n",
    "        plt.savefig('./plots/%s' %fig_name,transparent=True)\n",
    "# plot all operators\n",
    "if not params['ma_flag']:\n",
    "    plot_result(epi_data,data_fvcorrected,x_continuum,y_continuum,x_finitelattice,y_finitelattice,params['operators'],'O_i.pdf')\n",
    "else:\n",
    "    print(\"Mixed action fit, skipping plot routines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not params['ma_flag']:\n",
    "    plot_result(epi_data,data_fvcorrected,x_continuum,y_continuum,x_finitelattice,y_finitelattice,['LR','LR_colormix'],'LR.pdf')\n",
    "else:\n",
    "    print(\"Mixed action fit, skipping plot routines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not params['ma_flag']:\n",
    "    plot_result(epi_data,data_fvcorrected,x_continuum,y_continuum,x_finitelattice,y_finitelattice,['S','S_colormix'],'S.pdf')\n",
    "else:\n",
    "    print(\"Mixed action fit, skipping plot routines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot O3\n",
    "if not params['ma_flag']:\n",
    "    plot_result(epi_data,data_fvcorrected,x_continuum,y_continuum,x_finitelattice,y_finitelattice,['V'],'V.pdf')\n",
    "else:\n",
    "    print(\"Mixed action fit, skipping plot routines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<center>\n",
    "    <span style=\"color: black; font-family: Helvetica; font-size: 2em\">\n",
    "        These calculations were made possible by\n",
    "    </span>\n",
    "</center>\n",
    "\n",
    "| | |\n",
    "|:---:|:---:|\n",
    "| [<img src='./data/incite_logo.png' width='200'/>](http://www.doeleadershipcomputing.org/)  | [<img src='./data/olcf_logo.png' width='320'/>](https://www.olcf.ornl.gov/) |\n",
    "| [<img src='./data/llnl_logo.png' width='640' />](https://hpc.llnl.gov/) | [<img src='./data/scidac_logo.png' width='350' />](http://www.scidac.gov/) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
